{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyAudioAnalysis import audioFeatureExtraction as aFE, audioBasicIO, \\\n",
    "audioAnalysis,audioSegmentation,audioVisualization,audioTrainTest\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import librosa\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import models,layers\n",
    "import os\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Flatten, Dropout, GRU\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def amplitude_in_time(wave_file,threshold_seconds,sampling_rate_Hz):\n",
    "    \n",
    "    \"\"\"this function gives you amplitude in time with a threshold settings\n",
    "    with PyAudioAnalysis data loading. \"\"\"\n",
    "    \n",
    "    Fs, X = audioBasicIO.readAudioFile(wave_file)\n",
    "    sampling_indexes = []\n",
    "    data_new=[]\n",
    "    np.arange(0,threshold_seconds*Fs,50)\n",
    "    sampling_indexes=sampling_indexes[::-1]\n",
    "    if len(X)/Fs > threshold_seconds:\n",
    "        X = X[0:threshold_seconds*Fs]\n",
    "        data_new=[]\n",
    "        for i in sampling_indexes:\n",
    "            data_new.append(X[i])\n",
    "        data_new = data_new[::-1]\n",
    "        data.append(data_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "paths={'peterbertley_Audio/Atraining_murmur':0,\n",
    "       'peterbertley_Audio/Atraining_normal':1,\n",
    "       'peterbertley_Audio/Atraining_extrahls':2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def create_amplitude_dataset(path_dict):\n",
    "    \"\"\" To create a dataset of amplitudes of the same length\"\"\"\n",
    "    for k,i in enumerate(paths.keys()):\n",
    "        for audio_file in os.listdir(i):\n",
    "            if audio_file.endswith(\".wav\"):\n",
    "                amplitude_in_time(i+'/'+str(audio_file),5,50)\n",
    "                target.append(list(paths.values())[k]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data=[]\n",
    "target=[]\n",
    "create_amplitude_dataset(paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data --> Data --> with amplitude (vector for sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amplitude_data():\n",
    "    target=[]\n",
    "    i=0\n",
    "    data=[]\n",
    "\n",
    "    for item in os.listdir('peterbertley_Audio/Atraining_murmur'):  #Atraining_normal   #Atraining_extrahls\n",
    "         if item.endswith(\".wav\"):\n",
    "                Fs, X = audioBasicIO.readAudioFile('peterbertley_Audio/Atraining_murmur/'+str(item))\n",
    "                X_temp = X[1:]\n",
    "                data.append(X_temp-X[:-1])\n",
    "                target.append(['0','murmur'])\n",
    "\n",
    "    for item in os.listdir('peterbertley_Audio/Atraining_normal'):    #Atraining_extrahls\n",
    "         if item.endswith(\".wav\"):\n",
    "                Fs, X = audioBasicIO.readAudioFile('peterbertley_Audio/Atraining_normal/'+str(item))\n",
    "                #X_temp = X[1:]\n",
    "                #data.append(X_temp-X[:-1])\n",
    "                data.append(data)\n",
    "                target.append(['1','normal'])\n",
    "\n",
    "    for item in os.listdir('peterbertley_Audio/Atraining_extrahls'):   \n",
    "         if item.endswith(\".wav\"):\n",
    "                Fs, X = audioBasicIO.readAudioFile('peterbertley_Audio/Atraining_extrahls/'+str(item))\n",
    "                X_temp = X[1:]\n",
    "                data.append(X_temp-X[:-1])\n",
    "                target.append(['2','extrahls'])\n",
    "    #Preprocessing\n",
    "    threshold = 5*Fs   #5 seconds threshols\n",
    "    sampling_indexes = np.arange(0,threshold,10)\n",
    "    drop=[]\n",
    "    for k,i in enumerate(data):\n",
    "        if len(i)<threshold:\n",
    "            drop.append(k)\n",
    "    drop = drop[::-1]  #reversing the order for the dropping\n",
    "    print('shape before dropping:',len(data),len(target))\n",
    "    for i in drop:\n",
    "        data.pop(i)\n",
    "        target.pop(i)\n",
    "    print('shape after dropping:',len(data),len(target))\n",
    "\n",
    "    # Making all the arrays of the same lengths, and sampling every 50 Hertz\n",
    "\n",
    "    for k,i in enumerate(data):\n",
    "        data[k]=i[:threshold]\n",
    "        #data[k]=i[sampling_indexes]\n",
    "    data = np.array(data)\n",
    "\n",
    "    # StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    data = scaler.fit_transform(data)\n",
    "\n",
    "    print('final shape of your data is: ',data.shape)\n",
    "\n",
    "    #Setting the target with categorical transformation\n",
    "\n",
    "    target = np.array(target)\n",
    "    target = target[:,0]\n",
    "\n",
    "    target = to_categorical(target)\n",
    "    print('final categorical target shape is:',target.shape)\n",
    "\n",
    "    # Splitting data in training and test set\n",
    "\n",
    "    X_train,X_test,y_train,y_test = train_test_split(data,target,test_size=0.4)\n",
    "    return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data --> Feature Extraction with FeatureExtraction of pyAudioAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction_pyaudio():\n",
    "    target=[]\n",
    "    i=0\n",
    "    data=[]\n",
    "\n",
    "    for item in os.listdir('peterbertley_Audio/Atraining_murmur'):  #Atraining_normal   #Atraining_extrahls\n",
    "         if item.endswith(\".wav\"):\n",
    "                Fs, X = audioBasicIO.readAudioFile('peterbertley_Audio/Atraining_murmur/'+str(item))\n",
    "                F, f_names = aFE.stFeatureExtraction(X, Fs, 0.050*Fs, 0.025*Fs)\n",
    "                data.append(F)\n",
    "                target.append(['0','murmur'])\n",
    "\n",
    "    for item in os.listdir('peterbertley_Audio/Atraining_normal'):    #Atraining_extrahls\n",
    "         if item.endswith(\".wav\"):\n",
    "                Fs, X = audioBasicIO.readAudioFile('peterbertley_Audio/Atraining_normal/'+str(item))\n",
    "                F, f_names = aFE.stFeatureExtraction(X, Fs, 0.050*Fs, 0.025*Fs)\n",
    "                data.append(F)\n",
    "                target.append(['1','normal'])\n",
    "\n",
    "    for item in os.listdir('peterbertley_Audio/Atraining_extrahls'):   \n",
    "         if item.endswith(\".wav\"):\n",
    "                Fs, X = audioBasicIO.readAudioFile('peterbertley_Audio/Atraining_extrahls/'+str(item))\n",
    "                F, f_names = aFE.stFeatureExtraction(X, Fs, 0.050*Fs, 0.025*Fs)\n",
    "                data.append(F)\n",
    "                target.append(['2','extrahls'])\n",
    "    #Data Preprocessing\n",
    "    #Defining the threshold\n",
    "    print('samples are ',len(data))\n",
    "    list_lengths =[]\n",
    "    for i in data:\n",
    "        list_lengths.append(i.shape[1])\n",
    "    threshold  =int(np.max(list_lengths)*.75)\n",
    "    print('The threshold is',threshold,'and represent the number of measurement for the every single feature', \n",
    "       'of the 32 features for each sample')\n",
    "    return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data --> Feature Extraction with stft of librosa - Windowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stft_librosa_data():\n",
    "    target=[]\n",
    "    i=0\n",
    "    data=[]\n",
    "\n",
    "    for item in os.listdir('peterbertley_Audio/Atraining_murmur'):  #Atraining_normal   #Atraining_extrahls\n",
    "         if item.endswith(\".wav\"):\n",
    "                y, sr = librosa.load('peterbertley_Audio/Atraining_murmur/'+str(item))\n",
    "                data.append(y)\n",
    "                target.append(['0','murmur'])\n",
    "\n",
    "    for item in os.listdir('peterbertley_Audio/Atraining_normal'):    #Atraining_extrahls\n",
    "         if item.endswith(\".wav\"):\n",
    "                y, sr = librosa.load('peterbertley_Audio/Atraining_normal/'+str(item))\n",
    "                data.append(y)\n",
    "                target.append(['1','normal'])\n",
    "\n",
    "    for item in os.listdir('peterbertley_Audio/Atraining_extrahls'):   \n",
    "         if item.endswith(\".wav\"):\n",
    "                y, sr = librosa.load('peterbertley_Audio/Atraining_extrahls/'+str(item))\n",
    "                data.append(y)\n",
    "                target.append(['2','extrahls'])\n",
    "    list=[]\n",
    "    for k,i in enumerate(data):\n",
    "        list.append(len(data[k]))\n",
    "    threshold = 160000  \n",
    "    drop=[]\n",
    "    for k,i in enumerate(data):\n",
    "        if len(i)<threshold:\n",
    "            drop.append(k)\n",
    "    drop = drop[::-1]  #reversing the order for the dropping\n",
    "    print('shape before dropping:',len(data),len(target))\n",
    "    for i in drop:\n",
    "        data.pop(i)\n",
    "        target.pop(i)\n",
    "    print('shape after dropping:',len(data),len(target))\n",
    "    # Making all the arrays of the same lengths, and sampling every 50 Hertz\n",
    "\n",
    "    for k,i in enumerate(data):\n",
    "        data[k]=i[:threshold]\n",
    "    data = np.array(data)\n",
    "    data_new = []\n",
    "    for k,i in enumerate(data):\n",
    "        data_new.append(librosa.core.stft(i,n_fft=2048,win_length=2048))\n",
    "    data = np.array(data_new)\n",
    "    #Setting the target with categorical transformation\n",
    "\n",
    "    target = np.array(target)\n",
    "    target = target[:,0]\n",
    "\n",
    "    target = to_categorical(target)\n",
    "    print('final categorical target shape is:',target.shape)\n",
    "\n",
    "    # Splitting data in training and test set\n",
    "\n",
    "    X_train,X_test,y_train,y_test = train_test_split(data,target,test_size=0.4)\n",
    "\n",
    "    print('number of sample is',len(X_train),'sample shape is',X_train[0].shape)\n",
    "    return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN - Feed Forward - Data with Windowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train,X_test,y_train,y_test = stft_librosa_data()\n",
    "X_train,X_test,y_train,y_test = amplitude_data()\n",
    "#X_train,X_test,y_train,y_test = feature_extraction_pyaudio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''len(X_train[0])\n",
    "indexes_filtering = np.arange(0,4410,5)\n",
    "indexes_filtering\n",
    "print(X_train.shape)\n",
    "X_train = X_train[:,indexes_filtering]\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "X_test = X_test[:,indexes_filtering]\n",
    "print(X_test.shape)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(4000, activation='relu',input_shape=(4410,)))#X_train.shape[1],X_train.shape[2],)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(2000, activation='relu'))\n",
    "model.add(layers.Dense(1000, activation='relu'))\n",
    "model.add(layers.Dense(300, activation='relu'))\n",
    "model.add(layers.Dense(50, activation='relu'))\n",
    "#model.add(layers.Flatten())\n",
    "model.add(layers.Dense(3,activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import losses\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = optimizers.rmsprop(lr=00.1)#, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='mean_squared_error', optimizer=sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(optimizer='adam',loss=losses.categorical_crossentropy,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train,y_train,\n",
    "    epochs=20,\n",
    "    batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacked LSTM for STFT windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = stft_librosa_data()\n",
    "#X_train,X_test,y_train,y_test = amplitude_data()\n",
    "#X_train,X_test,y_train,y_test = feature_extraction_pyaudio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expected input data shape: (batch_size, timesteps, data_dim)\n",
    "model = Sequential()\n",
    "model.add(LSTM(1000,input_shape=(X_train.shape[1],X_train.shape[2]),return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(500,activation='relu',return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train,epochs=10)   #,batch_size=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN - Feed Forward - Data with amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = stft_librosa_data()\n",
    "#X_train,X_test,y_train,y_test = amplitude_data()\n",
    "#X_train,X_test,y_train,y_test = feature_extraction_pyaudio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(2000, activation='relu',input_shape=(4410)))\n",
    "model.add(layers.Dense(1000, activation='relu'))\n",
    "model.add(layers.Dense(500, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(3,activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train,y_train,\n",
    "    epochs=20,\n",
    "    batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN - Feed Forward - Data with Feature Extraction¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = stft_librosa_data()\n",
    "#X_train,X_test,y_train,y_test = amplitude_data()\n",
    "#X_train,X_test,y_train,y_test = feature_extraction_pyaudio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(20000, activation='relu',input_shape=(34,269,)))\n",
    "model.add(layers.Dense(5000, activation='relu'))\n",
    "model.add(layers.Dense(2000, activation='relu'))\n",
    "model.add(layers.Dense(50, activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(3,activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train,y_train,\n",
    "    epochs=10,\n",
    "    batch_size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacked LSTM for Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X_train.shape,y_train.shape)\n",
    "#X_train = X_train.reshape(X_train.shape[0],1,X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = stft_librosa_data()\n",
    "#X_train,X_test,y_train,y_test = amplitude_data()\n",
    "#X_train,X_test,y_train,y_test = feature_extraction_pyaudio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expected input data shape: (batch_size, timesteps, data_dim)\n",
    "model = Sequential()\n",
    "model.add(LSTM(1000,input_shape=(34,269,),return_sequences=True))\n",
    "model.add(LSTM(500,activation='relu',return_sequences=False))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train,epochs=10)   #,batch_size=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape)\n",
    "X_test = X_test.reshape(X_test.shape[0],1,X_test.shape[1])\n",
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network with amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train,X_test,y_train,y_test = stft_librosa_data()\n",
    "#X_train,X_test,y_train,y_test = amplitude_data()\n",
    "X_train,X_test,y_train,y_test = feature_extraction_pyaudio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expected input data shape: (batch_size, timesteps, data_dim)\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(500,input_shape=(34,240),return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(300,activation='relu',return_sequences=True))    \n",
    "model.add(LSTM(100,activation='relu',return_sequences=False))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train,batch_size=4,epochs=30)   #,batch_size=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('lstm1.h5')   #del model  (deletes the existing model)  #model = load_model('my_model.h5')\n",
    "# returns a compiled model\n",
    "# identical to the previous one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y,sr = librosa.load('my_heart_3.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(y),sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stft = librosa.core.stft(y,n_fft=2048,win_length=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(stft))\n",
    "stft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(stft).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.angle(stft).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN - GRU - Data with Windowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = stft_librosa_data()\n",
    "#X_train,X_test,y_train,y_test = amplitude_data()\n",
    "#X_train,X_test,y_train,y_test = feature_extraction_pyaudio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(GRU(500,input_shape=(1025, 313),return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GRU(300,activation='relu',return_sequences=True)) \n",
    "model.add(Dropout(0.2))\n",
    "model.add(GRU(100,activation='relu',return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train,y_train,\n",
    "    epochs=10,\n",
    "    batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target=[]\n",
    "i=0\n",
    "data=[]\n",
    "\n",
    "for item in os.listdir('peterbertley_Audio/Atraining_murmur'):  #Atraining_normal   #Atraining_extrahls\n",
    "     if item.endswith(\".wav\"):\n",
    "            Fs, X = audioBasicIO.readAudioFile('peterbertley_Audio/Atraining_murmur/'+str(item))\n",
    "            data.append(X)\n",
    "            target.append('0')\n",
    "\n",
    "for item in os.listdir('peterbertley_Audio/Atraining_normal'):    #Atraining_extrahls\n",
    "     if item.endswith(\".wav\"):\n",
    "            Fs, X = audioBasicIO.readAudioFile('peterbertley_Audio/Atraining_normal/'+str(item))\n",
    "            data.append(X)\n",
    "            target.append('1')\n",
    "threshold = 4*Fs   #5 seconds threshols\n",
    "sampling_indexes = np.arange(0,threshold,50)\n",
    "drop=[]\n",
    "for k,i in enumerate(data):\n",
    "    if len(i)<threshold:\n",
    "        drop.append(k)\n",
    "drop = drop[::-1]  #reversing the order for the dropping\n",
    "print('shape before dropping:',len(data),len(target))\n",
    "for i in drop:\n",
    "    data.pop(i)\n",
    "    target.pop(i)\n",
    "print('shape after dropping:',len(data),len(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,i in enumerate(data):\n",
    "    data[k]=i[:threshold]\n",
    "    data[k]=i[sampling_indexes]\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target = to_categorical(target)\n",
    "print('final categorical target shape is:')\n",
    "\n",
    "# Splitting data in training and test set\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(data,target,test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ExTC = ExtraTreesClassifier(n_estimators=1000,criterion='entropy',n_jobs=-1,random_state=2)\n",
    "model_ExTC.fit(X_train,y_train)\n",
    "print(model_ExTC.score(X_test,y_test))\n",
    "confusion_matrix(model_ExTC.predict(X_test),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_RFC = RandomForestClassifier(n_estimators=1000,criterion='entropy',n_jobs=-1,random_state=2)\n",
    "model_RFC.fit(X_train,y_train)\n",
    "print(model_RFC.score(X_test,y_test))\n",
    "confusion_matrix(model_RFC.predict(X_test),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_DTC = DecisionTreeClassifier(criterion='entropy',random_state=2)\n",
    "model_DTC.fit(X_train,y_train)\n",
    "print(model_DTC.score(X_test,y_test))\n",
    "confusion_matrix(model_DTC.predict(X_test),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_GBC = GradientBoostingClassifier(loss='deviance', learning_rate=0.1, \n",
    "                       n_estimators=100, subsample=1.0, criterion='friedman_mse')\n",
    "model_GBC.fit(X_train,y_train)\n",
    "model_GBC.score(X_test,y_test)\n",
    "confusion_matrix(model_GBC.predict(X_test),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_GNB = GaussianNB()\n",
    "model.fit(X_train,y_train)\n",
    "model.score(X_test,y_test)\n",
    "confusion_matrix(model.predict(X_test),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape before dropping: 53 53\n",
      "shape after dropping: 47 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luigibungaro/dsr/lib/python3.6/site-packages/sklearn/utils/validation.py:444: DataConversionWarning: Data with input dtype int16 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-ee311f72e9a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dsr/lib/python3.6/site-packages/keras/utils/np_utils.py\u001b[0m in \u001b[0;36mto_categorical\u001b[0;34m(y, num_classes)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mis\u001b[0m \u001b[0mplaced\u001b[0m \u001b[0mlast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \"\"\"\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "target=[]\n",
    "i=0\n",
    "data=[]\n",
    "\n",
    "for item in os.listdir('peterbertley_Audio/Atraining_murmur'):  #Atraining_normal   #Atraining_extrahls\n",
    "     if item.endswith(\".wav\"):\n",
    "            Fs, X = audioBasicIO.readAudioFile('peterbertley_Audio/Atraining_murmur/'+str(item))\n",
    "            data.append(X)\n",
    "            target.append('0')\n",
    "            \n",
    "for item in os.listdir('peterbertley_Audio/Atraining_extrahls'):   \n",
    "     if item.endswith(\".wav\"):\n",
    "            Fs, X = audioBasicIO.readAudioFile('peterbertley_Audio/Atraining_extrahls/'+str(item))\n",
    "            data.append(X)\n",
    "            target.append(['1'])\n",
    "\n",
    "threshold = 5*Fs   #5 seconds threshols\n",
    "drop=[]\n",
    "for k,i in enumerate(data):\n",
    "    if len(i)<threshold:\n",
    "        drop.append(k)\n",
    "drop = drop[::-1]  #reversing the order for the dropping\n",
    "print('shape before dropping:',len(data),len(target))\n",
    "for i in drop:\n",
    "    data.pop(i)\n",
    "    target.pop(i)\n",
    "print('shape after dropping:',len(data),len(target))\n",
    "\n",
    "for k,i in enumerate(data):\n",
    "    data[k]=i[:threshold]\n",
    "    #data[k]=i[sampling_indexes]\n",
    "data = np.array(data)\n",
    "\n",
    "# StandardScaler\n",
    "scaler = StandardScaler()\n",
    "data = scaler.fit_transform(data)\n",
    "\n",
    "target = to_categorical(target)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(data,target,test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_models():\n",
    "    \n",
    "    model_ExTC = ExtraTreesClassifier(n_estimators=1000,criterion='entropy',n_jobs=-1,random_state=2)\n",
    "    model_ExTC.fit(X_train,y_train)\n",
    "    print('model_ExTC',model_ExTC.score(X_test,y_test))\n",
    "    print(confusion_matrix(model_ExTC.predict(X_test),y_test))\n",
    "    \n",
    "    model_RFC = RandomForestClassifier(n_estimators=1000,criterion='entropy',n_jobs=-1,random_state=2)\n",
    "    model_RFC.fit(X_train,y_train)\n",
    "    print('model_RFC',model_RFC.score(X_test,y_test))\n",
    "    print(confusion_matrix(model_RFC.predict(X_test),y_test))\n",
    "          \n",
    "    model_DTC = DecisionTreeClassifier(criterion='entropy',random_state=2)\n",
    "    model_DTC.fit(X_train,y_train)\n",
    "    print('model_DTC',model_DTC.score(X_test,y_test))\n",
    "    print(confusion_matrix(model_DTC.predict(X_test),y_test))\n",
    "          \n",
    "    model_GBC = GradientBoostingClassifier(loss='deviance', learning_rate=0.1, \n",
    "                       n_estimators=100, subsample=1.0, criterion='friedman_mse')\n",
    "    model_GBC.fit(X_train,y_train)\n",
    "    print('model_GBC',model_GBC.score(X_test,y_test))\n",
    "    print(confusion_matrix(model_GBC.predict(X_test),y_test))\n",
    "          \n",
    "    model_GNB = GaussianNB()\n",
    "    model_GNB.fit(X_train,y_train)\n",
    "    print('model_GNB',model_GNB.score(X_test,y_test))\n",
    "    print(confusion_matrix(model_GNB.predict(X_test),y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-867aa21251c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclassification_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-37-126bb143bf07>\u001b[0m in \u001b[0;36mclassification_models\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmodel_ExTC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExtraTreesClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'entropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmodel_ExTC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_ExTC'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_ExTC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_ExTC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dsr/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;31m# Validate or convert input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dsr/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    400\u001b[0m                                       force_all_finite)\n\u001b[1;32m    401\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence"
     ]
    }
   ],
   "source": [
    "classification_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape before dropping: 84 84\n",
      "shape after dropping: 76 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luigibungaro/dsr/lib/python3.6/site-packages/sklearn/utils/validation.py:444: DataConversionWarning: Data with input dtype int16 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final shape of your data is:  (76, 220500)\n",
      "final categorical target shape is: (76, 3)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-014228a5e513>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel_RFC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'entropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel_RFC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_RFC'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_RFC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#print(confusion_matrix(model_RFC.predict(X_test),y_test))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dsr/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_more_estimators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 tree = self._make_estimator(append=False,\n\u001b[0;32m--> 315\u001b[0;31m                                             random_state=random_state)\n\u001b[0m\u001b[1;32m    316\u001b[0m                 \u001b[0mtrees\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dsr/lib/python3.6/site-packages/sklearn/ensemble/base.py\u001b[0m in \u001b[0;36m_make_estimator\u001b[0;34m(self, append, random_state)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0m_set_random_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mappend\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dsr/lib/python3.6/site-packages/sklearn/ensemble/base.py\u001b[0m in \u001b[0;36m_set_random_states\u001b[0;34m(estimator, random_state)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mto_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'random_state'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'__random_state'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mto_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_RAND_SEED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dsr/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mget_params\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;31m# This is set in utils/__init__.py but it gets overwritten\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             \u001b[0;31m# when running under python3 somehow.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"always\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDeprecationWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/warnings.py\u001b[0m in \u001b[0;36msimplefilter\u001b[0;34m(action, category, lineno, append)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlineno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlineno\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m            \u001b[0;34m\"lineno must be an int >= 0\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m     \u001b[0m_add_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlineno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_add_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/warnings.py\u001b[0m in \u001b[0;36m_add_filter\u001b[0;34m(append, *item)\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0m_add_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlineno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0m_add_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m     \u001b[0;31m# Remove possible duplicate filters, so new one will be placed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;31m# in correct place. If append=True and duplicate exists, do nothing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = amplitude_data()\n",
    "\n",
    "model_RFC = RandomForestClassifier(n_estimators=10000,criterion='entropy',n_jobs=-1,random_state=2)\n",
    "model_RFC.fit(X_train,y_train)\n",
    "print('model_RFC',model_RFC.score(X_test,y_test))\n",
    "#print(confusion_matrix(model_RFC.predict(X_test),y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expected input data shape: (batch_size, timesteps, data_dim)\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(3000,input_shape=(X_train.shape[1],1),return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(1000,activation='relu',return_sequences=True))    \n",
    "model.add(LSTM(200,activation='relu',return_sequences=False))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train,y_train,batch_size=234,epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(300, activation='relu',input_shape=(X_train.shape[1],1)))#X_train.shape[1],X_train.shape[2],)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(100, activation='relu'))\n",
    "model.add(layers.Dense(50, activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(3,activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train, y_train,batch_size=1056,epochs=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-427f7c4e90e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape before dropping: 84 84\n",
      "shape after dropping: 76 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luigibungaro/dsr/lib/python3.6/site-packages/sklearn/utils/validation.py:444: DataConversionWarning: Data with input dtype int16 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final shape of your data is:  (76, 220500)\n",
      "final categorical target shape is: (76, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = amplitude_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0],1,X_train.shape[1])\n",
    "X_test = X_test.reshape(X_test.shape[0],1,X_test.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.reshape(y_train.shape[0],1,y_train.shape[1])\n",
    "y_test = y_test.reshape(y_test.shape[0],1,y_test.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "45/45 [==============================] - 4s 94ms/step - loss: 1.0939 - acc: 0.3778\n",
      "Epoch 2/30\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.9847 - acc: 0.6444\n",
      "Epoch 3/30\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.9418 - acc: 0.7556\n",
      "Epoch 4/30\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.9015 - acc: 0.8222\n",
      "Epoch 5/30\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.8737 - acc: 0.8889\n",
      "Epoch 6/30\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.8601 - acc: 0.8889\n",
      "Epoch 7/30\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.8489 - acc: 0.8667\n",
      "Epoch 8/30\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.8415 - acc: 0.8667\n",
      "Epoch 9/30\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.8347 - acc: 0.8667\n",
      "Epoch 10/30\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.8286 - acc: 0.8667\n",
      "Epoch 11/30\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.8210 - acc: 0.8667\n",
      "Epoch 12/30\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.8138 - acc: 0.8667\n",
      "Epoch 13/30\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.8081 - acc: 0.8889\n",
      "Epoch 14/30\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.8021 - acc: 0.8667\n",
      "Epoch 15/30\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.7966 - acc: 0.8667\n",
      "Epoch 16/30\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.7912 - acc: 0.8667\n",
      "Epoch 17/30\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.7858 - acc: 0.8667\n",
      "Epoch 18/30\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.7806 - acc: 0.8667\n",
      "Epoch 19/30\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.7754 - acc: 0.8667\n",
      "Epoch 20/30\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.7703 - acc: 0.8889\n",
      "Epoch 21/30\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.7652 - acc: 0.8889\n",
      "Epoch 22/30\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.7602 - acc: 0.8889\n",
      "Epoch 23/30\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.7552 - acc: 0.8889\n",
      "Epoch 24/30\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.7503 - acc: 0.8889\n",
      "Epoch 25/30\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.7454 - acc: 0.8889\n",
      "Epoch 26/30\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.7387 - acc: 0.9111\n",
      "Epoch 27/30\n",
      "45/45 [==============================] - 1s 20ms/step - loss: 0.7337 - acc: 0.9111\n",
      "Epoch 28/30\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.7284 - acc: 0.9111\n",
      "Epoch 29/30\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.7233 - acc: 0.9111\n",
      "Epoch 30/30\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.7184 - acc: 0.9111\n",
      "31/31 [==============================] - 0s 15ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0271623134613037, 0.5161290168762207]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# expected input data shape: (batch_size, timesteps, data_dim)\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(32,input_shape=(X_train.shape[1],X_train.shape[2]),return_sequences=True))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(LSTM(8,activation='relu',return_sequences=True))    \n",
    "#model.add(LSTM(100,activation='relu',return_sequences=False))\n",
    "#model.add(Flatten())\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train,batch_size=132,epochs=30)   #,batch_size=3\n",
    "\n",
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in os.listdir('peterbertley_Audio/Atraining_normal'):    #Atraining_extrahls\n",
    "     if item.endswith(\".wav\"):\n",
    "            Fs, X = audioBasicIO.readAudioFile('peterbertley_Audio/Atraining_normal/'+str(item))\n",
    "            data.append(X)\n",
    "            target.append('1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
